{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cmapPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, precision_score, label_ranking_average_precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm, preprocessing\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/reactome_term_dicts.pickle', 'rb') as handle:\n",
    "    reactome_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DepMap response data to various drugs\n",
    "GI50 (proliferation rate change) per cell line for various drugs\n",
    "\n",
    "Formatting the data to be cell_line by drug name. Data is stored in multiple files using various namings conventions. Converting to CCLE and generic drug name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_response = pd.read_csv('data/depmap_data/primary-screen-replicate-collapsed-logfold-change.csv')\n",
    "\n",
    "cl_response.rename({'Unnamed: 0': 'cell_line'}, axis=1, inplace=True)\n",
    "cell_lines_in_treatment = set(cl_response.cell_line.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cell_lines_in_treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_response.set_index('cell_line', inplace=True)\n",
    "\n",
    "cl_response.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_response.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canonical cell line names\n",
    "cell_lines = pd.read_csv('data/depmap_data/primary-screen-cell-line-info.csv')\n",
    "# quick dict for naming\n",
    "rowname_to_cell_line = cell_lines[['row_name', 'ccle_name']].copy()\n",
    "rowname_to_cell_line.set_index('row_name', inplace=True)\n",
    "rowname_to_cell_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename cell lines\n",
    "cl_response.rename(rowname_to_cell_line.to_dict()['ccle_name'], inplace=True)\n",
    "cl_response = cl_response.reset_index().set_index('cell_line')\n",
    "# cl_response.dropna(inplace=True, axis=0)\n",
    "cl_response.fillna(value=cl_response.mean(), inplace=True)\n",
    "cl_response.sort_index(inplace=True, ascending=False)\n",
    "cl_response.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_response.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get canonical drug names, \n",
    "drugs = pd.read_csv('data/depmap_data/primary-screen-replicate-collapsed-treatment-info.csv')\n",
    "drugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_drug = drugs[['column_name', 'name']].drop_duplicates().set_index('column_name').to_dict()['name']\n",
    "#renmae column names to drug names\n",
    "cl_response.rename(columns=rename_drug, inplace=True)\n",
    "cl_response.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sclc = cl_response.loc[cl_response.index.str.contains('LUNG')]\n",
    "plt.title(f'{sclc.shape[1]} drugs: {sclc.shape[0]} cell lines')\n",
    "\n",
    "sns.heatmap(sclc)\n",
    "plt.savefig('heatmap_depmap_gi50.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNAseq from CCLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmapPy.pandasGEXpress.parse import parse\n",
    "# ccle_rna = parse('data/ccle/CCLE_RNAseq_genes_rpkm_20180929.gct')\n",
    "ccle_rna = pd.read_csv('data/depmap_data/CCLE_expression.csv')\n",
    "ccle_rna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_gene = ccle_rna.row_metadata_df.reset_index()[['rid', 'Description']].drop_duplicates().set_index('rid').to_dict()['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_rna_d = ccle_rna.data_df.copy()\n",
    "ccle_cl_names = list(ccle_rna_d.columns)\n",
    "\n",
    "ccle_rna_d.reset_index(inplace=True)\n",
    "\n",
    "ccle_rna_d.columns.name = None\n",
    "ccle_rna_d.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename ENSG ids to HGNC names\n",
    "ccle_rna_d['rid'] = ccle_rna_d['rid'].map(rename_gene)\n",
    "ccle_rna_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some genes have duplicate measurments. Weird for RNAseq but will average out for meantime\n",
    "ccle_rna_d = ccle_rna_d.groupby(['rid']).mean().reset_index()\n",
    "ccle_genes = list(ccle_rna_d['rid'])\n",
    "ccle_genes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_rna_d.set_index('rid', inplace=True)\n",
    "ccle_rna_d.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot so cell line is each row\n",
    "ccle_rna_d = ccle_rna_d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_rna_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_rna_d.index.name =  'cell_line'\n",
    "ccle_rna_d.columns.name = None\n",
    "ccle_rna_d.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_rna_d.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_std = list(ccle_rna_d.std()[ccle_rna_d.std() > 5].index.values)\n",
    "print(len(good_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_response.head(5)\n",
    "drugs = list(cl_response.columns)\n",
    "drugs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_response.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proteomics = pd.read_csv('data/ccle/protein_quant_current_normalized.csv.gz')\n",
    "# proteomics.head()\n",
    "# cl_col = [i for i in sorted(proteomics.columns.values) if 'Ten' in i]\n",
    "# cl_prefix = [i.split('_Ten')[0] for i in cl_col]\n",
    "\n",
    "# print(set(cl_prefix).intersection(set(ccle_cl_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_df = pd.DataFrame.from_dict(reactome_dict)\n",
    "reactome_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weird case where some of the drugs are genes? Removing from drug side\n",
    "# all_but = set(ccle_rna_d.columns).intersection(cl_response.columns)\n",
    "\n",
    "all_but = set(cl_response.columns)\n",
    "gene_drugs = ['LTA', 'NPPB', 'PRIMA1']\n",
    "for i in gene_drugs:\n",
    "    all_but.discard(i)\n",
    "# [genes expression cols] + [drug response]\n",
    "merged = ccle_rna_d.join(cl_response[all_but], how='inner')\n",
    "# average cell line expression for drugs/expression\n",
    "# should probably do this before and see where its coming from\n",
    "merged = merged.reset_index().groupby(['cell_line']).mean()\n",
    "merged = merged.loc[:,~merged.columns.duplicated()]\n",
    "merged.dropna(inplace=True)\n",
    "print(merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_hdf('data.h5', key='df', mode='w')\n",
    "merged = pd.read_hdf('data.h5', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\n",
    "\n",
    "def create_elasticnet(df, drugname, subset_list, save_name):\n",
    "    subset_genes = list(sorted(set(subset_list).intersection(set(df.columns.values))))\n",
    "    X = df[subset_genes].copy()\n",
    "    y = df[drugname].copy()\n",
    "    X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "#     poly = PolynomialFeatures(degree=2)\n",
    "#     X = poly.fit_transform(X)\n",
    "     \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2, \n",
    "        shuffle=True, \n",
    "        random_state=69,\n",
    "    )\n",
    "    \n",
    "    print(X_train.shape, y_train.shape)\n",
    "#     model = svm.SVR(gamma=0.001, C=100.)\n",
    "#     model.fit(X_train, y_train)\n",
    "    model = ElasticNet(random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    plt.subplot(111)\n",
    "    t_preds = model.predict(X_train)\n",
    "    sns.regplot(y_train, t_preds, label='training')\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    error = mean_squared_error(y_test, preds)\n",
    "    sns.regplot(y_test, preds, label='prediction')\n",
    "    plt.legend()\n",
    "    plt.suptitle(f\"{drugname} {save_name} : RMSE = {error}\")\n",
    "    \n",
    "create_elasticnet(merged, 'ABT-737', apop_genes, 'apoptosis_subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apop_genes = reactome_df.loc[reactome_df.term=='apoptosis homo sapiens r-hsa-109581']['gene_list'].values\n",
    "apop_genes = list(apop_genes[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_svm(df, drugname, subset_list, save_name):\n",
    "    subset_genes = list(sorted(set(subset_list).intersection(set(df.columns.values))))\n",
    "    X = df[subset_genes].copy()\n",
    "    y = df[drugname].copy()\n",
    "    X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "#     poly = PolynomialFeatures(degree=2)\n",
    "#     X = poly.fit_transform(X)\n",
    "     \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2, \n",
    "        shuffle=True, \n",
    "        random_state=69,\n",
    "    )\n",
    "    \n",
    "    print(X_train.shape, y_train.shape)\n",
    "    model = svm.SVR(gamma=0.001, C=100.)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    plt.subplot(111)\n",
    "    t_preds = model.predict(X_train)\n",
    "    sns.regplot(y_train, t_preds, label='training')\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    error = mean_squared_error(y_test, preds)\n",
    "    sns.regplot(y_test, preds, label='prediction')\n",
    "    plt.legend()\n",
    "    plt.suptitle(f\"{drugname} {save_name} : RMSE = {error}\")\n",
    "    \n",
    "create_svm(merged, 'ABT-737', apop_genes, 'apoptosis_subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_ccle_gn = list(sorted(good_std))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost parameters\n",
    "\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "params = dict(\n",
    "    # general params\n",
    "    booster='gbtree',\n",
    "    gpu_id=0,\n",
    "    seed=100,\n",
    "    # regularization\n",
    "    reg_alpha=1, \n",
    "    reg_lambda=5,\n",
    "    num_parallel_tree = 4, \n",
    "#     num_boost_round = 16,\n",
    "    tree_method='gpu_hist',\n",
    "    max_bin=256,\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5, \n",
    "    min_child_weight=1,\n",
    "#     gamma=0,\n",
    "    subsample=.5, # use half of data to resample\n",
    "#     colsample_bytree=.8,\n",
    ")\n",
    "\n",
    "def create_importance_model(df, drugname, subset_list, save_name):\n",
    "    subset_genes = list(sorted(set(subset_list).intersection(set(df.columns.values))))\n",
    "    X = df[subset_genes]\n",
    "    y = df[drugname]\n",
    "    X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    X = poly.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2, \n",
    "        shuffle=True, \n",
    "        random_state=69,\n",
    "    )\n",
    "\n",
    "    \n",
    "    # organize data into xgb data matrix\n",
    "    all_data = xgb.DMatrix(data=X, label=y)\n",
    "    train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    test = xgb.DMatrix(data=X_test, label=y_test)\n",
    "\n",
    "    # add gene names as feature labels\n",
    "#     all_data.feature_names = subset_genes\n",
    "#     train.feature_names = subset_genes\n",
    "#     test.feature_names = subset_genes\n",
    "    \n",
    "    num_round = 100000\n",
    "    results = dict()\n",
    "    model = xgb.train(\n",
    "        params, train, num_round,\n",
    "        verbose_eval=False,\n",
    "        early_stopping_rounds=100,\n",
    "        evals=[(train, 'train'), (test, 'valid')],\n",
    "        evals_result=results,\n",
    "        \n",
    "    )  \n",
    "    \n",
    "    feature_scores = model.get_fscore()\n",
    "    s = pd.Series(list(feature_scores.values()), index=feature_scores)\n",
    "    print(s.sort_values(ascending=False).head(5))\n",
    "    # retrieve performance metrics\n",
    "    epochs = len(results['train']['rmse'])\n",
    "    x_axis = range(0, epochs)\n",
    "    # plot log loss\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(x_axis, results['train']['rmse'], label='Train')\n",
    "    plt.plot(x_axis, results['valid']['rmse'], label='Test')\n",
    "    plt.legend()\n",
    "    \n",
    "    #trained \n",
    "    t_preds = model.predict(train, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "    #predictions\n",
    "    preds = model.predict(test)\n",
    "    error = mean_squared_error(y_test, preds)\n",
    "    error = \"{0:.3f}\".format(np.sqrt(error))\n",
    "    print(f\"MSE: {error}\")\n",
    "\n",
    "    # simple plot\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    sns.regplot(y_train, t_preds, label='training')\n",
    "    sns.regplot(y_test, preds, label='prediction')\n",
    "    plt.legend()\n",
    "    plt.suptitle(f\"{drugname} {save_name} : RMSE = {error}\")\n",
    "\n",
    "    plt.savefig(f'pred_{save_name}.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_importance_model(merged, 'ABT-737', sort_ccle_gn, 'apoptosis_subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = sorted([i for i in drugs if isinstance(i, str)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for i in drugs[:5]:\n",
    "    errors.append(create_importance_model(merged, 'ABT-737', apop_genes, 'apoptosis_subset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_genes = reactome_df.loc[reactome_df.term=='cell cycle homo sapiens r-hsa-1640170']['gene_list'].values\n",
    "cc_genes = list(cc_genes[0])\n",
    "create_importance_model(merged, 'ABT-737', cc_genes, 'cc_subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_terms = reactome_df.loc[(reactome_df.n_genes<1000) & (reactome_df.n_genes>500)].term.values\n",
    "for i in big_terms:\n",
    "    savename = i.replace(' ', '_').split('_homo')[0]\n",
    "    genes = reactome_df.loc[reactome_df.term==i]['gene_list'].values\n",
    "    create_importance_model(merged, drugs[0], set(list(genes)[0]), savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_parameter_scan(df, drugname):\n",
    "    X = df[sort_ccle_gn]\n",
    "    y = df[drugname]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2, \n",
    "        shuffle=False, \n",
    "        random_state=123,\n",
    "    )\n",
    "\n",
    "    # organize data into xgb data matrix\n",
    "    train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    test = xgb.DMatrix(data=X_test, label=y_test)\n",
    "\n",
    "    # add gene names as feature labels\n",
    "    train.feature_names = sort_ccle_gn\n",
    "    test.feature_names = sort_ccle_gn\n",
    "    num_round = 1000\n",
    "\n",
    "    param_tuning = {\n",
    "        'learning_rate': [0.1],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "#         'min_child_weight': [1, 3, 5],\n",
    "        'subsample': [0.5, 0.7],\n",
    "        'objective': ['reg:squarederror'],\n",
    "        'tree_method' : ['gpu_hist'],\n",
    "        'eval_metric' :['rmse'],\n",
    "        'reg_alpha':[1], \n",
    "        'reg_lambda':[30], \n",
    "        'num_parallel_tree':[4], \n",
    "    \n",
    "    }\n",
    "\n",
    "    xgb_model = XGBRegressor(\n",
    "        n_estimators=num_round, \n",
    "        n_jobs=12,\n",
    "        booster='gbtree'\n",
    "    )\n",
    "\n",
    "    gsearch = GridSearchCV(\n",
    "        estimator=xgb_model,\n",
    "        param_grid=param_tuning,               \n",
    "        cv=2,\n",
    "        n_jobs=1,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    gsearch.fit(\n",
    "        X_train, y_train, \n",
    "        early_stopping_rounds=50, \n",
    "#         eval_metric=\"mae\",\n",
    "        eval_set=[[X_train, y_train], [X_test, y_test]],\n",
    "        verbose=False\n",
    "    )\n",
    "    print(gsearch.best_params_)\n",
    "    \n",
    "        #trained \n",
    "    t_preds = gsearch.predict(X_train)\n",
    "    #predictions\n",
    "    preds = gsearch.predict(X_test)\n",
    "    error = mean_squared_error(y_test, preds)\n",
    "    error = \"{0:.3f}\".format(np.sqrt(error))\n",
    "    \n",
    "    print(f\"MSE: {error}\")\n",
    "\n",
    "    # simple plot\n",
    "    plt.figure()\n",
    "    plt.subplot(111)\n",
    "    sns.regplot(y_train, t_preds, label='training')\n",
    "    sns.regplot(y_test, preds, label='prediction')\n",
    "    plt.legend()\n",
    "    plt.suptitle(f\"{drugname} : RMSE = {error}\")\n",
    "\n",
    "    plt.savefig(f'pred_{drugname}.png')\n",
    "    return gsearch.best_params_\n",
    "# run_parameter_scan(merged, drugs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = dict()\n",
    "for i in drugs[0:10]:\n",
    "    best_params[i] = run_parameter_scan(merged, i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, D_out)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.Tanh = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        y_pred = self.dropout(self.linear1(x))\n",
    "        y_pred = self.dropout(self.Tanh(y_pred))\n",
    "        y_pred = self.dropout(self.linear2(y_pred))\n",
    "        y_pred = self.dropout(self.Tanh(y_pred))\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from copy import deepcopy\n",
    "def run_nn(df, gene_list, save_name, drugname, verbose=False):\n",
    "    torch.cuda.empty_cache()\n",
    "    dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     print(drugname)\n",
    "#     dev = 'cpu'\n",
    "#     print('Using device:', dev)\n",
    "    ib = list(set(gene_list).intersection(set(df.columns.values)))\n",
    "    # ib = list(set(good_std).intersection(numeric_data.columns.values))\n",
    "    X = df[ib].values\n",
    "    y = df[drugs].values#.reshape(-1,1)\n",
    "    X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "    y = preprocessing.StandardScaler().fit(y).transform(y)\n",
    "#     poly = PolynomialFeatures(degree=2)\n",
    "#     X = poly.fit_transform(X)\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            test_size=0.5, \n",
    "            shuffle=True, \n",
    "            random_state=69,\n",
    "        )\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "    dtype = torch.float32\n",
    "    X_train = torch.tensor(X_train, dtype=dtype,  device=dev)\n",
    "    X_test = torch.tensor(X_test, dtype=dtype,  device=dev)\n",
    "\n",
    "    y_train = torch.tensor(y_train, dtype=dtype,  device=dev)\n",
    "    y_test = torch.tensor(y_test, dtype=dtype,  device=dev)\n",
    "\n",
    "#     print(X_train.shape, y_train.shape)\n",
    "    D_in, D_out = X_train.shape[1], y_train.shape[1]\n",
    "    H1 = int((D_in+D_out)/2)\n",
    "#     H1 = 100\n",
    "    model = Net(D_in, H1, D_out)\n",
    "    model.to(dev)\n",
    "    model.float()\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=1e-4,\n",
    "        betas=(0.9, 0.999), \n",
    "        eps=1e-08, \n",
    "        weight_decay=0,\n",
    "        amsgrad=True\n",
    "    )\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "#     optimizer = torch.optim.ASGD(\n",
    "#         model.parameters(), lr=0.01, lambd=0.001, \n",
    "#         alpha=0.0, t0=1000.0, weight_decay=0.\n",
    "#     )\n",
    "\n",
    "    n_epoch = 10000\n",
    "    eval_per_epoch = n_epoch//10\n",
    "    prev_loss = np.inf\n",
    "    steps_wo_impro = 0\n",
    "    best_state = deepcopy(model.state_dict())\n",
    "    best_epoch = 0\n",
    "    st = time.time()\n",
    "    train, valid = [], []\n",
    "    for epoch in range(n_epoch):\n",
    "        if steps_wo_impro > eval_per_epoch:\n",
    "#             print(f\"Early stopping at {epoch}\")\n",
    "            break\n",
    "        model.train()\n",
    "        \n",
    "        # use original method\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        if torch.isnan(loss):\n",
    "            break        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "        \n",
    "            test_loss = criterion(model(X_test), y_test).item()\n",
    "\n",
    "            train.append(loss.item())\n",
    "            valid.append(test_loss)\n",
    "\n",
    "            if test_loss < prev_loss:\n",
    "                prev_loss = deepcopy(test_loss)\n",
    "                steps_wo_impro = 0\n",
    "                best_state = deepcopy(model.state_dict())\n",
    "                best_epoch = epoch\n",
    "            else:\n",
    "                steps_wo_impro += 1\n",
    "    #         if epoch < 1000:\n",
    "    #             steps_wo_impro = 0\n",
    "    #             prev_loss = np.inf\n",
    "            if verbose:\n",
    "                if (epoch+1) % eval_per_epoch == 0:\n",
    "                    print(\n",
    "                        'Epoch [{}/{}], Loss train: {:2.4e}, test {:2.4e} \\\n",
    "                        '.format(epoch+1, n_epoch, loss.item(), test_loss)\n",
    "                    )\n",
    "#     print(f'time : {time.time()-st}')\n",
    "    del model\n",
    "    \n",
    "    test_model = Net(D_in, H1, D_out)\n",
    "    test_model.load_state_dict(best_state)\n",
    "    test_model.float()\n",
    "    test_model.to(dev)\n",
    "    test_model.eval()\n",
    "    \n",
    "    train_pred = test_model(X_train).cpu().detach().numpy()\n",
    "    train_actual = y_train.cpu().detach().numpy()\n",
    "    \n",
    "    error = mean_squared_error(train_pred, train_actual)\n",
    "    error = \"{0:.3f}\".format(np.sqrt(error))\n",
    "#     print(f\"Best epoch = {best_epoch} with error = {prev_loss} {np.sqrt(prev_loss)}\")\n",
    "#     print(f\"\\t {error}\")  \n",
    "    \n",
    "    test_pred = test_model(X_test).cpu().detach().numpy()\n",
    "    test_actual =  y_test.cpu().numpy()\n",
    "    error = mean_squared_error(test_pred, test_actual)\n",
    "#     return np.sqrt(error)\n",
    "    error = \"{0:.3f}\".format(np.sqrt(error))\n",
    "    \n",
    "    print(f\"\\t {error}\")  \n",
    "    \n",
    "    # simple plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(121)\n",
    "    x_axis = range(0, len(train))\n",
    "    plt.plot(best_epoch, prev_loss, marker='^')\n",
    "    plt.plot(x_axis, train, label='Train')\n",
    "    plt.plot(x_axis, valid, label='Test')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(122)\n",
    "    sns.regplot(train_pred[:,0], train_actual[:,0], label='Training')\n",
    "    sns.regplot(test_pred[:,0], test_actual[:,0], label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.suptitle(f\"{drugname} {save_name} : RMSE = {error}\")\n",
    "#     plt.close()\n",
    "    return np.sqrt(mean_squared_error(test_pred, test_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_nn(merged, set(merged.columns.values), 'ABT-737', 'ABT-737', True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "big_terms = list(reactome_df.loc[(reactome_df.n_genes<200) & (reactome_df.n_genes>100)].term.values)\n",
    "# big_terms = list(reactome_df.loc[reactome_df.n_genes>100].term.values)\n",
    "n_drugs = len(drugs[:])\n",
    "print(len(big_terms[:]))\n",
    "print(n_drugs)\n",
    "for i in tqdm(drugs[:200], desc = 'Drugs'):\n",
    "#     for j in tqdm(big_terms[:20], desc = 'Terms'):\n",
    "    for j in big_terms[:]:\n",
    "#         continue\n",
    "        genes = list(reactome_df.loc[reactome_df.term==j]['gene_list'].values)[0]\n",
    "        errors.append([i, j, run_nn(merged, genes, i,i)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messed_up_errors = deepcopy(errors)\n",
    "count = 0\n",
    "for i in drugs[:200]:\n",
    "    for j in big_terms[:]:\n",
    "        pname = j.split(' homo')[0]\n",
    "        messed_up_errors[count].insert(1, pname)\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame(messed_up_errors, columns=['drug', 'pathway', 'error'])\n",
    "error_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_df = error_df.pivot(index='drug', columns='pathway', values='error')\n",
    "error_df = pd.pivot_table(error_df, index='drug', columns='pathway', values='error')\n",
    "error_df.dropna(inplace=True)\n",
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(error_df, figsize=(18, 22), cmap=sns.cubehelix_palette(as_cmap=True), vmax=1);\n",
    "plt.savefig('drug_by_term.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(drugs[:200], desc = 'Drugs'):\n",
    "#     for j in tqdm(big_terms[:20], desc = 'Terms'):\n",
    "    for j in big_terms[:]:\n",
    "#         continue\n",
    "        genes = list(reactome_df.loc[reactome_df.term==j]['gene_list'].values)[0]\n",
    "        errors.append([i, j.split(' homo')[0], run_nn(merged, genes, i,i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame(errors, columns=['drug', 'pathway', 'error'])\n",
    "error_df = error_df.pivot(index='drug', columns='pathway', values='error')\n",
    "error_df.dropna(inplace=True)\n",
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(error_df, figsize=(12, 12), cmap=sns.cubehelix_palette(as_cmap=True), vmax=1);\n",
    "plt.savefig('drug_by_term.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_genes = reactome_df.loc[reactome_df.term=='cell cycle homo sapiens r-hsa-1640170']['gene_list'].values\n",
    "cc_genes = list(cc_genes[0])\n",
    "for i in drugs[:2]:\n",
    "    run_nn(merged, cc_genes, i, i, True)\n",
    "#     run_nn(good_std, i, i, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_genes = reactome_df.loc[reactome_df.term=='cell cycle homo sapiens r-hsa-1640170']['gene_list'].values\n",
    "cc_genes = list(cc_genes[0])\n",
    "for i in drugs:\n",
    "#     run_nn(cc_genes, i, i, True)\n",
    "    run_nn(good_std, i, i, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_genes = reactome_df.loc[reactome_df.term=='cell cycle homo sapiens r-hsa-1640170']['gene_list'].values\n",
    "cc_genes = list(cc_genes[0])\n",
    "run_nn(cc_genes, 'cc', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_terms = list(reactome_df.loc[(reactome_df.n_genes<500) & (reactome_df.n_genes>100)].term.values)\n",
    "for i in big_terms[:]:\n",
    "    print(i)\n",
    "    savename = i.replace(' ', '_').split('_homo')[0]\n",
    "    genes = list(reactome_df.loc[reactome_df.term==i]['gene_list'].values)[0]\n",
    "    run_nn(genes, 'savename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_terms = list(reactome_df.loc[(reactome_df.n_genes<1000) & (reactome_df.n_genes>500)].term.values)\n",
    "for i in big_terms[:]:\n",
    "    print(i)\n",
    "    savename = i.replace(' ', '_').split('_homo')[0]\n",
    "    genes = list(reactome_df.loc[reactome_df.term==i]['gene_list'].values)[0]\n",
    "    run_nn(genes, 'savename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connectivety map data \n",
    "We will use fold change data of the CMAPs 12,328 genes\n",
    "![title](https://clue.io/connectopedia/images/data_levels_images/image_0.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_cl = pd.read_csv('data/LINCS/cellinfo_beta.txt', delimiter='\\t')\n",
    "cmap_cl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_ccle_cl = set(cmap_cl.dropna(subset=['ccle_name']).ccle_name.values)\n",
    "\n",
    "overlap = treatment.reset_index()\n",
    "overlap = overlap.loc[overlap.cell_line.isin(cmap_ccle_cl)]\n",
    "overlap.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.title(f'{overlap.shape[1]} drugs: {overlap.shape[0]} cell lines')\n",
    "overlap.set_index('cell_line', inplace=True)\n",
    "sns.heatmap(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_gn = pd.read_csv('data/LINCS/geneinfo_beta.txt', delimiter='\\t')\n",
    "cmap_gn.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cmap_gn.gene_symbol.unique())\n",
    "cmap_genes = set(cmap_gn.gene_symbol.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCLE expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_mirna = pd.read_csv('data/ccle/CCLE_RNAseq_genes_rpkm_20180929.gct',\n",
    "                         delimiter='\\t', skiprows=2)\n",
    "print(ccle_mirna.shape)\n",
    "ccle_mirna = ccle_mirna.loc[ccle_mirna.Description.isin(cmap_genes)]\n",
    "print(ccle_mirna.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_mirna.set_index('Description', inplace=True)\n",
    "ccle_mirna.drop('Name', axis=1, inplace=True)\n",
    "ccle_mirna.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_mirna.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_mirna.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(i for i in ccle_mirna.columns if i.startswith('PC')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(i for i in ccle_mirna.columns if i.startswith('H') and 'LUNG' in i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_mirna.T.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_mirna.T.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = set(ccle_mirna.columns.values)\n",
    "inboth = cols.intersection(cmap_ccle_cl)\n",
    "\n",
    "print(ccle_mirna.shape)\n",
    "ccle_mirna_filtered = ccle_mirna[inboth]\n",
    "print(ccle_mirna_filtered.shape)\n",
    "ccle_mirna_filtered = ccle_mirna_filtered[ccle_mirna_filtered.T.mean() > 1]\n",
    "ccle_mirna_filtered = ccle_mirna_filtered[(ccle_mirna_filtered.T.std()/ccle_mirna_filtered.T.mean()) > 1]\n",
    "print(ccle_mirna_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccle_mirna_filtered.T.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.boxplot(data=ccle_mirna_filtered.T[['PLCH2', 'NPPB']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(ccle_mirna_filtered, vmax=10, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.clustermap(ccle_mirna_filtered, vmax=10, figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
